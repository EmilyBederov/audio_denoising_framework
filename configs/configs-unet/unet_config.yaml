# configs/configs-unet/unet-config.yaml
# UNet configuration that matches your framework structure

# Model parameters
model_name: unet
input_channels: 1
output_channels: 1
base_channels: 32
depth: 3

# Audio processing parameters (UNet-specific)
sample_rate: 16000
frame_length: 0.032  # STFT window width in seconds
frame_shift: 0.016   # STFT window shift in seconds
num_frames: 16       # Number of frames per input segment

# Normalization parameters (computed from training data)
min_val: -9.188868273733446
max_val: -0.2012536819610933

# Training parameters
batch_size: 16
epochs: 30
learning_rate: 0.0001
weight_decay: 0.0001

# Data paths (modify these to match your data structure)
trainset:
  csv_path: "data/audio_data/training_pairs_16khz.csv"

valset:
  csv_path: "data/audio_data/evaluation_pairs_16khz.csv"

# Optional test set
testset:
  csv_path: "data/audio_data/evaluation_pairs_16khz.csv"

# Data processing parameters that match your existing data loader
n_fft: 1024
hop_length: 256
win_length: 1024
power: 1.0
max_length: 65536  # Maximum audio length

# Worker settings
num_workers: 4

# Checkpointing
save_path: "outputs/unet"

# Loss function
loss_type: "l1"  # Can be 'l1', 'mse', or 'huber'